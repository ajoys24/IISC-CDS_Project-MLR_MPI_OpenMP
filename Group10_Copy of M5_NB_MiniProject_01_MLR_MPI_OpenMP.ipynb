{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[{"file_id":"1MK5OgOG9Sy3-2853wzLElogBuwF-khPT","timestamp":1747547811860},{"file_id":"1kgyo26G7gC4IVxVdpz8IUGT493uEW8os","timestamp":1746901301271}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7rc1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"heated-queens"},"source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Mini-Project: Implementation of Multiple Linear Regression using MPI and OpenMP"],"id":"heated-queens"},{"cell_type":"markdown","metadata":{"id":"military-proportion"},"source":["## Learning Objectives"],"id":"military-proportion"},{"cell_type":"markdown","metadata":{"id":"durable-grounds"},"source":["At the end of the mini-project, you will be able to :\n","\n","* understand the collective communication operations like scatter, gather, broadcast\n","* understand the blocking and non-blocking communication\n","* implement multiple linear regression and run it using MPI\n","* implement the multiple linear regression based predictions using OpenMP"],"id":"durable-grounds"},{"cell_type":"markdown","metadata":{"id":"growing-queens"},"source":["### Dataset"],"id":"growing-queens"},{"cell_type":"markdown","metadata":{"id":"yLwz-D_xVT8o"},"source":["The dataset chosen for this mini-project is [Combined Cycle Power Plant](https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant). The dataset is made up of 9568 records and 5 columns. Each record contains the values for Ambient Temperature, Exhaust Vaccum, Ambient Pressure, Relative Humidity and Energy Output.\n","\n","Predicting full load electrical power output of a base load power plant is important in order to maximize the profit from the available megawatt hours.  The base load operation of a power plant is influenced by four main parameters, which are used as input variables in the dataset, such as ambient temperature, atmospheric pressure, relative humidity, and exhaust steam pressure. These parameters affect electrical power output, which is considered as the target variable.\n","\n","**Note:** The data was collected over a six year period (2006-11)."],"id":"yLwz-D_xVT8o"},{"cell_type":"markdown","metadata":{"id":"dominant-residence"},"source":["## Information"],"id":"dominant-residence"},{"cell_type":"markdown","metadata":{"id":"coated-timing"},"source":["#### MPI in a Nutshell\n","\n","MPI stands for \"Message Passing Interface\". It is a library of functions (in C / Python) or subroutines (in Fortran) that you insert into source code to perform data communication between processes. MPI was developed over two years of discussions led by the MPI Forum, a group of roughly sixty people representing some forty organizations.\n","\n","To know more about MPI click [here](https://hpc-tutorials.llnl.gov/mpi/)\n","\n","\n","#### Multiple Linear Regression\n","\n","Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable). The variables we are using to predict the value of the dependent variable are called the independent variables (or sometimes, the predictor, explanatory or regressor variables)."],"id":"coated-timing"},{"cell_type":"markdown","metadata":{"id":"global-savings"},"source":["**Note:** We will be using the mpi4py Python package for MPI based code implementation"],"id":"global-savings"},{"cell_type":"markdown","metadata":{"id":"ndQNKsjS7c04"},"source":["## Grading = 20 Points"],"id":"ndQNKsjS7c04"},{"cell_type":"markdown","metadata":{"id":"green-deviation"},"source":["**Run the below code to install mpi4py package**"],"id":"green-deviation"},{"cell_type":"code","metadata":{"id":"designing-marketing","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747498518652,"user_tz":-330,"elapsed":162770,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"1dc60471-a01b-48a9-b8d2-dd43035cf748"},"source":["!pip install mpi4py"],"id":"designing-marketing","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/466.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m460.8/466.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4438170 sha256=2530967a4b16259d3d4fda345c3a0be4f30a976bed2e7240e6e18efb0a20a54c\n","  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-4.0.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"dedicated-thong"},"source":["#### Importing Necessary Packages"],"id":"dedicated-thong"},{"cell_type":"code","metadata":{"id":"reported-acrobat","scrolled":true},"source":["# Importing pandas\n","import pandas as pd\n","# Importing Numpy\n","import numpy as np\n","# Importing MPI from mpi4py package\n","from mpi4py import MPI\n","# Importing sqrt function from the Math\n","from math import sqrt\n","# Importing Decimal, ROUND_HALF_UP functions from the decimal package\n","from decimal import Decimal, ROUND_HALF_UP\n","from sklearn.preprocessing import StandardScaler\n","import time"],"id":"reported-acrobat","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"standing-zimbabwe"},"source":["#### Downloading the data"],"id":"standing-zimbabwe"},{"cell_type":"code","metadata":{"id":"universal-jonathan","scrolled":true,"cellView":"form"},"source":["#@title Download the data\n","!wget -qq https://cdn.iisc.talentsprint.com/CDS/Datasets/PowerPlantData.csv"],"id":"universal-jonathan","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"forty-still"},"source":["### Overview\n","\n","* Load the data and perform data pre-processing\n","* Identify the features, target and split the data into train and test\n","* Implement multiple Linear Regression by estimating the coefficients on the given data\n","* Use MPI package to distribute the data and implement `communicator`\n","* Define functions for each objective and make a script (.py) file to execute using MPI command\n","* Use OpenMP component to predict the data and calculate the error on the predicted data\n","* Implement the Linear Regression from `sklearn` and compare the results"],"id":"forty-still"},{"cell_type":"markdown","metadata":{"id":"early-peace"},"source":["#### Exercise 1: Load data (1 point)\n","\n","Write a function that takes the filename as input and loads the data in a pandas dataframe with the column names as Ambient Temperature, Exhaust Vaccum, Ambient Pressure, Relative Humidity and Energy Output respectively.\n","\n","**Hint:** read_csv()\n"],"id":"early-peace"},{"cell_type":"code","metadata":{"id":"differential-vacation","scrolled":true},"source":["FILENAME = \"/content/PowerPlantData.csv\" # File path\n","\n","# YOUR CODE HERE to Define a function to load the data\n","df = pd.read_csv(FILENAME)"],"id":"differential-vacation","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"italian-expense"},"source":["#### Exercise 2: Explore data (1 point)\n","\n","Write a function that takes the data loaded using the above defined function as input and explore it.\n","\n","**Hint:** You can define and check for following things in the dataset inside a function\n","\n","- checking for the number of rows and columns\n","- summary of the dataset\n","- check for the null values\n","- check for the duplicate values"],"id":"italian-expense"},{"cell_type":"code","metadata":{"id":"local-quarter","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747498523219,"user_tz":-330,"elapsed":129,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"4ff458dc-3f9d-4142-855b-31d59773a621"},"source":["# YOUR CODE HERE\n","print(df.shape)\n","print(df.info())\n","print(df.describe())\n","print(df.isnull().sum())\n","print(len(df[df.duplicated()]))"],"id":"local-quarter","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(9568, 5)\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9568 entries, 0 to 9567\n","Data columns (total 5 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   AT      9568 non-null   float64\n"," 1   V       9568 non-null   float64\n"," 2   AP      9568 non-null   float64\n"," 3   RH      9568 non-null   float64\n"," 4   PE      9568 non-null   float64\n","dtypes: float64(5)\n","memory usage: 373.9 KB\n","None\n","                AT            V           AP           RH           PE\n","count  9568.000000  9568.000000  9568.000000  9568.000000  9568.000000\n","mean     19.651231    54.305804  1013.259078    73.308978   454.365009\n","std       7.452473    12.707893     5.938784    14.600269    17.066995\n","min       1.810000    25.360000   992.890000    25.560000   420.260000\n","25%      13.510000    41.740000  1009.100000    63.327500   439.750000\n","50%      20.345000    52.080000  1012.940000    74.975000   451.550000\n","75%      25.720000    66.540000  1017.260000    84.830000   468.430000\n","max      37.110000    81.560000  1033.300000   100.160000   495.760000\n","AT    0\n","V     0\n","AP    0\n","RH    0\n","PE    0\n","dtype: int64\n","41\n"]}]},{"cell_type":"markdown","metadata":{"id":"whole-retailer"},"source":["#### Exercise 3: Handle missing data (1 point)\n","\n","After exploring the dataset if there are any null values present in the dataset then define a function that takes data loaded using the above defined function as input and handle the null values accordingly.\n","\n","**Hint:**\n","\n","- Drop the records containing the null values - dropna()\n","- Replace the null values with the mean/median/mode - fillna()"],"id":"whole-retailer"},{"cell_type":"code","metadata":{"id":"incorporated-child","scrolled":true},"source":["# Function to handle missing data\n","\n","# YOUR CODE HERE"],"id":"incorporated-child","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"loaded-arbitration"},"source":["#### Exercise 4: Scale the data (1 point)\n","\n","Write a function that takes the data after handling the missing data as input and returns the standardized data.\n","\n","**Hint:**\n","\n","- standardization of the data  can be performed using the below formula\n","\n","$ (x - mean(x)) / std(x) $"],"id":"loaded-arbitration"},{"cell_type":"code","metadata":{"id":"extraordinary-qatar","scrolled":true},"source":["# Defining a function to standardize the data\n","\n","# YOUR CODE HERE\n","def scale_data(df):\n","\n","    scaler = StandardScaler()\n","    scaler.fit(df)\n","    scaled_data = scaler.transform(df)\n","\n","    return(pd.DataFrame(scaled_data, columns=df.columns, index = df.index))"],"id":"extraordinary-qatar","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"thermal-rehabilitation"},"source":["#### Exercise 5: Feature selection (1 point)\n","\n","Write a function that takes scaled data as input and returns the features and target variable values\n","\n","**Hint:**\n","\n","- Features: AmbientTemperature, ExhaustVaccum, AmbientPressure, RelativeHumidity\n","- Target Variable: EnergyOutput"],"id":"thermal-rehabilitation"},{"cell_type":"code","metadata":{"id":"terminal-starter","scrolled":true},"source":["# Define a function\n","\n","# YOUR CODE HERE\n","def split_data(df):\n","\n","    feature_cols = ['AT','V','AP','RH']\n","    target_col = ['PE']\n","\n","    features = df[feature_cols]\n","    target = df[target_col]\n","\n","    return features,target"],"id":"terminal-starter","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"timely-bruce"},"source":["#### Exercise 6: Correlation (1 point)\n","\n","Calculate correlation between the variables"],"id":"timely-bruce"},{"cell_type":"code","metadata":{"id":"durable-making","scrolled":true},"source":["# YOUR CODE HERE\n","def calculate_corelation(df):\n","    return df.corr()"],"id":"durable-making","execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr_matrix = calculate_corelation(scale_data(df))\n","print(corr_matrix)"],"metadata":{"id":"Cr3ppFKGZEe0","executionInfo":{"status":"ok","timestamp":1747498523445,"user_tz":-330,"elapsed":111,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"ea9ea580-497f-4959-e633-18281cdd23f6","colab":{"base_uri":"https://localhost:8080/"}},"id":"Cr3ppFKGZEe0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["          AT         V        AP        RH        PE\n","AT  1.000000  0.844107 -0.507549 -0.542535 -0.948128\n","V   0.844107  1.000000 -0.413502 -0.312187 -0.869780\n","AP -0.507549 -0.413502  1.000000  0.099574  0.518429\n","RH -0.542535 -0.312187  0.099574  1.000000  0.389794\n","PE -0.948128 -0.869780  0.518429  0.389794  1.000000\n"]}]},{"cell_type":"markdown","metadata":{"id":"honest-remainder"},"source":["#### Exercise 7: Estimate the coefficients (2 points)\n","\n","Write a function that takes features and target as input and returns the estimated coefficient values\n","\n","**Hint:**\n","\n","- Calculate the estimated coefficients using the below formula\n","\n","$ β = (X^T X)^{-1} X^T y $\n","\n","- transpose(), np.linalg.inv()"],"id":"honest-remainder"},{"cell_type":"code","metadata":{"id":"dimensional-victory","scrolled":true},"source":["# Calculating the coeffients\n","\n","# YOUR CODE HERE\n","def calculate_coff(features,target):\n","    X = features.to_numpy()\n","    y = target.to_numpy()\n","\n","    X_transpose = X.T\n","    coeff = np.linalg.inv(X_transpose @ X) @ X_transpose @ y\n","    return coeff"],"id":"dimensional-victory","execution_count":null,"outputs":[]},{"cell_type":"code","source":["features, target = split_data(scale_data(df))\n","coeff = calculate_coff(features, target)\n","print(coeff)"],"metadata":{"id":"7A5vbxlaaqia","executionInfo":{"status":"ok","timestamp":1747498523488,"user_tz":-330,"elapsed":44,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"dc3a8926-ebd5-4e44-d831-a06a94bcce1c","colab":{"base_uri":"https://localhost:8080/"}},"id":"7A5vbxlaaqia","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.86350078]\n"," [-0.17417154]\n"," [ 0.02160293]\n"," [-0.13521023]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"interior-bennett"},"source":["#### Exercise 8: Fit the data to estimate the coefficients (2 points)\n","\n","Write a function named fit which takes features and targets as input and returns the intercept and coefficient values.\n","\n","**Hint:**\n","\n","- create a dummy column in the features dataframe which is made up of all ones\n","- convert the features dataframe into numpy array\n","- call the estimated coefficients function which is defined above\n","- np.ones(), np.concatenate()"],"id":"interior-bennett"},{"cell_type":"code","metadata":{"id":"local-texas","scrolled":true},"source":["# defining a fit function\n","def fit(x, y):\n","    # YOUR CODE HERE\n","    x['Dummy'] = 1\n","    print(x.head(1))\n","    coeff = calculate_coff(x,y)\n","    return coeff\n"],"id":"local-texas","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coeff = fit(features, target)\n","print(coeff[:4])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9gpZ3v10riY","executionInfo":{"status":"ok","timestamp":1747498523583,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"18b37c80-1602-4943-f937-28e2acf9202d"},"id":"O9gpZ3v10riY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         AT         V        AP        RH  Dummy\n","0 -1.517862 -1.065205 -0.407357  1.143944      1\n","[[-0.86350078]\n"," [-0.17417154]\n"," [ 0.02160293]\n"," [-0.13521023]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"hybrid-quick"},"source":["#### Exercise 9: Predict the data on estimated coefficients (1 point)\n","\n","Write a function named predict which takes features, intercept and coefficient values as input and returns the predicted values.\n","\n","**Hint:**\n","\n","- Fit the intercept, coefficients values in the below equation\n","\n","  $y = b_0 + b_1*x + ... + b_i*x_i$"],"id":"hybrid-quick"},{"cell_type":"code","metadata":{"id":"buried-attention","scrolled":true},"source":[" # fucntion to predict the values\n","def predict(x, intercept, coefficients):\n","    '''\n","    y = b_0 + b_1*x + ... + b_i*x_i\n","    '''\n","    #YOUR CODE HERE\n","    coefficients = coefficients.flatten()\n","    intercept = intercept.flatten()\n","\n","    predictions = np.zeros(x.shape[0])\n","\n","    for index, row in x.reset_index(drop=True).iterrows():\n","            predictions[index] = intercept + np.dot(coefficients, row.iloc[:len(coefficients)])\n","\n","    predictions_df = pd.DataFrame(predictions,columns=['PE_Pred'])\n","    return predictions_df"],"id":"buried-attention","execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = predict(features,coeff[4],coeff[:4])\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuZ2wXXO4Mee","executionInfo":{"status":"ok","timestamp":1747498527272,"user_tz":-330,"elapsed":3643,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"3a9c9dbd-7e0b-433f-c4e4-fa7f76d2c4b4"},"id":"CuZ2wXXO4Mee","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-39becd870d04>:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  predictions[index] = intercept + np.dot(coefficients, row.iloc[:len(coefficients)])\n"]},{"output_type":"stream","name":"stdout","text":["       PE_Pred\n","0     1.332730\n","1    -0.534559\n","2    -0.936009\n","3     0.076408\n","4     0.889608\n","...        ...\n","9563  0.597073\n","9564 -1.803272\n","9565  0.528409\n","9566 -0.022664\n","9567 -0.411558\n","\n","[9568 rows x 1 columns]\n"]}]},{"cell_type":"markdown","metadata":{"id":"rolled-consultancy"},"source":["#### Exercise 10: Root mean squared error (1 point)\n","\n","Write a function to calculate the RMSE error.\n","\n","**Hint:**\n","\n","- [How to calculate the RSME error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e)"],"id":"rolled-consultancy"},{"cell_type":"code","metadata":{"id":"phantom-alabama","scrolled":true},"source":["# Define a function to calculate the error\n","\n","# YOUR CODE HERE\n","def calculate_rsme(target,prediction):\n","    target = target.to_numpy()\n","    prediction = prediction.to_numpy()\n","\n","    squared_errors = (prediction - target) ** 2\n","    mean_squared_error = np.mean(squared_errors)\n","\n","    rmse_value = np.sqrt(mean_squared_error)\n","\n","    return rmse_value"],"id":"phantom-alabama","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rsme = calculate_rsme(target,prediction)\n","print(rsme)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUB9_7iy8qP6","executionInfo":{"status":"ok","timestamp":1747498975019,"user_tz":-330,"elapsed":19,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"cd3636d8-c907-481c-c4dc-0fac1914f2db"},"id":"IUB9_7iy8qP6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.26702792024008715\n"]}]},{"cell_type":"markdown","metadata":{"id":"experimental-discrimination"},"source":["#### Exercise 11: Split the data into train and test (1 point)\n","\n","Write a function named train_test_split which takes features and targets as input and returns the train and test sets respectively.\n","\n","**Hint:**\n","\n","- Shuffle the data\n","- Consider 70 % of data as a train set and the rest of the data as a test set"],"id":"experimental-discrimination"},{"cell_type":"code","metadata":{"id":"dangerous-salmon","scrolled":true},"source":["# YOUR CODE HERE\n","def train_test_split(X):\n","    X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n","    num_rows = int(0.7 * len(X))\n","    remain_rows = len(X) - num_rows\n","    train = X.iloc[:num_rows, :].copy()\n","    test = X.tail(remain_rows).copy()\n","    return train, test"],"id":"dangerous-salmon","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train,test = train_test_split(scale_data(df))\n","print(train.shape,test.shape)\n","print(train.head(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz7bUuSx_CZr","executionInfo":{"status":"ok","timestamp":1747498527366,"user_tz":-330,"elapsed":41,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"d244611c-6d13-4620-cafc-770c0f1d56a4"},"id":"gz7bUuSx_CZr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(6697, 5) (2871, 5)\n","         AT         V        AP        RH        PE\n","0  1.348451  0.239564 -1.284687 -1.093118 -1.236077\n"]}]},{"cell_type":"code","source":["prediction = predict(test,coeff[4],coeff[:4])\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGyd1noej85B","executionInfo":{"status":"ok","timestamp":1747507619489,"user_tz":-330,"elapsed":177,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"e1d70f2d-60d4-499f-dfc6-c7f42856f0c2"},"id":"VGyd1noej85B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       PE_Pred\n","0    -0.512701\n","1    -1.607746\n","2    -0.997989\n","3     1.447719\n","4     1.348577\n","...        ...\n","2866 -0.843814\n","2867 -1.121608\n","2868  0.455895\n","2869 -0.968580\n","2870  1.658825\n","\n","[2871 rows x 1 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-55-8c0aff652542>:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  predictions[index] = intercept + np.dot(coefficients, row.iloc[:len(coefficients)])\n"]}]},{"cell_type":"markdown","metadata":{"id":"living-operation"},"source":["#### Exercise 12: Implement predict using OpenMP (1 point)\n","\n","Get the predictions for test data and calculate the test error(RMSE) by implementing the OpenMP (pymp)\n","\n","**Hints:**\n","\n","* Using the pymp.Parallel implement the predict function (use from above)\n","\n","* Call the predict function by passing test data as an argument\n","\n","* calculate the error (RMSE) by comparing the Actual test data and predicted test data"],"id":"living-operation"},{"cell_type":"code","source":["!pip install pymp-pypi"],"metadata":{"id":"1PndfF9b_mkN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747498537791,"user_tz":-330,"elapsed":10418,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"c0fd362a-49cb-40af-8aa8-e3205f2993b2"},"id":"1PndfF9b_mkN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymp-pypi\n","  Downloading pymp-pypi-0.5.0.tar.gz (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pymp-pypi\n","  Building wheel for pymp-pypi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymp-pypi: filename=pymp_pypi-0.5.0-py3-none-any.whl size=10314 sha256=b00f491c7c2c3fd6b57777e5ee51ebadcee0446955c900e08d7aa37e91ce711c\n","  Stored in directory: /root/.cache/pip/wheels/3d/6c/ef/356575a818508a9c37c4513a5139063d522ea002bcebd15bbe\n","Successfully built pymp-pypi\n","Installing collected packages: pymp-pypi\n","Successfully installed pymp-pypi-0.5.0\n"]}]},{"cell_type":"code","source":["import pymp\n","# YOUR CODE HERE\n","\n","def predict_parallel(x, intercept, coefficients):\n","    '''\n","    y = b_0 + b_1*x + ... + b_i*x_i\n","    '''\n","    #YOUR CODE HERE\n","    coefficients = coefficients.flatten()\n","    intercept = intercept.flatten()\n","\n","    num_rows = x.shape[0]\n","    predictions = pymp.shared.array((num_rows,),dtype='float64')\n","\n","    with pymp.Parallel(4) as p:\n","        for index in p.range(0, num_rows):\n","            row = x.iloc[index]\n","            predictions[index] = (intercept + np.dot(coefficients, row.iloc[:len(coefficients)])).item()\n","\n","    predictions_df = pd.DataFrame(predictions,columns=['PE_Pred'])\n","    return predictions_df\n"],"metadata":{"id":"o8DSppnV_wQa"},"id":"o8DSppnV_wQa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_feature, test_target = split_data(test)\n","pred = predict_parallel(test_feature,coeff[4],coeff[:4])\n","print(calculate_rsme(test_target,pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBtrwM5qAoDs","executionInfo":{"status":"ok","timestamp":1747499155701,"user_tz":-330,"elapsed":347,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"a19833b6-20db-4644-a3b8-04dba6a519cd"},"id":"SBtrwM5qAoDs","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2650547913407178\n"]}]},{"cell_type":"markdown","metadata":{"id":"covered-canon"},"source":["#### Exercise 13: Create a communicator (1 point)\n","\n","Create a comunicator and define the rank and size"],"id":"covered-canon"},{"cell_type":"code","metadata":{"id":"radio-origin","scrolled":true},"source":["# YOUR CODE HERE\n","from mpi4py import MPI\n","comm = MPI.COMM_WORLD\n","rank = comm.Get_rank()\n","size = comm.Get_size()"],"id":"radio-origin","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miniature-plaza"},"source":["#### Exercise 14: Divide the data into slices (1 point)\n","\n","Write a function named dividing_data which takes train features set, train target set, and size of workers as inputs and returns the sliced data for each worker.\n","\n","![img](https://cdn.iisc.talentsprint.com/CDS/Images/MiniProject_MPI_DataSlice.JPG)\n","\n","For Example, if there are 4 processes, slice the data into 4 equal parts with 25% ratio\n","\n","**Hint:**\n","\n","- Divide the Data equally among the workers\n","  - Create an empty list\n","  - Iterate over the size of workers\n","  - Append each slice of data to the list"],"id":"miniature-plaza"},{"cell_type":"code","metadata":{"id":"signal-medicaid","scrolled":true},"source":["def dividing_data(x_train, y_train, size_of_workers):\n","    # Size of the slice\n","    worker_data = []\n","\n","    slice_for_each_worker = int(Decimal(x_train.shape[0]/size_of_workers).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))\n","    print('Slice of data for each worker: {}'.format(slice_for_each_worker))\n","    # YOUR CODE HERE\n","\n","    row_num = 0\n","    i = 0\n","    for i in range(size_of_workers):\n","\n","        end_index = row_num+slice_for_each_worker\n","        end_index = min(end_index, len(x_train))\n","        print(end_index)\n","\n","        worker_data.append((x_train.iloc[row_num:end_index, :].copy(),\n","                            y_train.iloc[row_num:end_index, :].copy()))\n","        row_num = end_index\n","\n","    return worker_data\n","\n"],"id":"signal-medicaid","execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = dividing_data(test_feature, test_target,4)\n","data[0][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"5tkO0j2qO_E2","executionInfo":{"status":"ok","timestamp":1747502273146,"user_tz":-330,"elapsed":68,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"94772f8d-429d-4b7f-980e-96e27311470b"},"id":"5tkO0j2qO_E2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Slice of data for each worker: 718\n","718\n","1436\n","2154\n","2871\n"]},{"output_type":"execute_result","data":{"text/plain":["            PE\n","6697 -0.804812\n","6698 -1.090759\n","6699 -0.767311\n","6700  1.687848\n","6701  0.910283\n","...        ...\n","7410  1.731209\n","7411  1.269475\n","7412  1.386080\n","7413  0.338390\n","7414  1.609330\n","\n","[718 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-27b558e3-7d59-4541-aeb3-75926b0c86c0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6697</th>\n","      <td>-0.804812</td>\n","    </tr>\n","    <tr>\n","      <th>6698</th>\n","      <td>-1.090759</td>\n","    </tr>\n","    <tr>\n","      <th>6699</th>\n","      <td>-0.767311</td>\n","    </tr>\n","    <tr>\n","      <th>6700</th>\n","      <td>1.687848</td>\n","    </tr>\n","    <tr>\n","      <th>6701</th>\n","      <td>0.910283</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7410</th>\n","      <td>1.731209</td>\n","    </tr>\n","    <tr>\n","      <th>7411</th>\n","      <td>1.269475</td>\n","    </tr>\n","    <tr>\n","      <th>7412</th>\n","      <td>1.386080</td>\n","    </tr>\n","    <tr>\n","      <th>7413</th>\n","      <td>0.338390</td>\n","    </tr>\n","    <tr>\n","      <th>7414</th>\n","      <td>1.609330</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>718 rows × 1 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27b558e3-7d59-4541-aeb3-75926b0c86c0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-27b558e3-7d59-4541-aeb3-75926b0c86c0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-27b558e3-7d59-4541-aeb3-75926b0c86c0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-88415fcb-2e9c-4d6c-980d-0439df33a6ae\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88415fcb-2e9c-4d6c-980d-0439df33a6ae')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-88415fcb-2e9c-4d6c-980d-0439df33a6ae button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"data[0][1]\",\n  \"rows\": 718,\n  \"fields\": [\n    {\n      \"column\": \"PE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0245239061765186,\n        \"min\": -1.7142173136469743,\n        \"max\": 2.371659796159718,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          1.6374558640519055,\n          -0.6196499192516053,\n          -1.370260643138365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"changing-conditioning"},"source":["#### Exercise 15: Prepare the data in root worker to assign data for all the workers (1 point)\n","\n","- When it is the root worker, perform the below operation:\n","    - Store the features and target values in separate variables\n","    - Split the data into train and test sets using the train_test_split function defined above\n","    - Divide the data among the workers using the dividing_data function above"],"id":"changing-conditioning"},{"cell_type":"code","metadata":{"id":"hybrid-tamil","scrolled":true},"source":["# YOUR CODE HERE\n","\n","if rank == 0:\n","    features, target = split_data(scale_data(df))\n","    X_train,X_test = train_test_split(features)\n","    y_train,y_test = train_test_split(target)\n","    worker_data = dividing_data(X_train, y_train, 4)\n"],"id":"hybrid-tamil","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"breathing-baking"},"source":["#### Exercise 16: Scatter and gather the data (1 point)\n","\n","Perform the below operations:\n","\n","- Send slices of the training set(the features data X and the expected target data Y) to every worker including the root worker\n","    - **Hint:** scatter()\n","    - use `barrier()` to block workers until all workers in the group reach a Barrier, to scatter from root worker.\n","- Every worker should get the predicted target Y(yhat) for each slice\n","- Get the new coefficient of each instance in a slice\n","    - **Hint:** fit function defined above\n","- Gather the new coefficient from each worker\n","    - **Hint:** gather()\n","    - Take the mean of the gathered coefficients\n","- Calculate the root mean square error for the test set\n","\n","To know more about `scatter`, `gather` and `barrier` click [here](https://nyu-cds.github.io/python-mpi/05-collectives/)"],"id":"breathing-baking"},{"cell_type":"code","metadata":{"id":"consistent-union","scrolled":true},"source":["# YOUR CODE HERE\n","recv_data = comm.scatter(worker_data,root=0)\n","comm.barrier()\n","\n","worker_coeff = fit(recv_data[0],recv_data[1])\n","recv_buff = None\n","recv_buff = comm.gather(worker_coeff,root=0)\n","\n","if rank == 0:\n","    print(recv_buff)\n","\n","\n","\n","\n","\n"],"id":"consistent-union","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hired-uniform"},"source":["#### Exercise 17: Make a script and execute everything in one place (1 point)\n","\n","Write a script(.py) file which contains the code of all the above exercises in it so that you can run the code on multiple processes using MPI.\n","\n","**Hint:**\n","\n","- magic commands\n","- put MPI related code under main function\n","- !mpirun --allow-run-as-root -np 4 python filename.py"],"id":"hired-uniform"},{"cell_type":"code","metadata":{"id":"motivated-national"},"source":["# YOUR CODE HERE for scipt(.py)\n","# Importing pandas\n","import pandas as pd\n","# Importing Numpy\n","import numpy as np\n","# Importing MPI from mpi4py package\n","from mpi4py import MPI\n","# Importing sqrt function from the Math\n","from math import sqrt\n","# Importing Decimal, ROUND_HALF_UP functions from the decimal package\n","from decimal import Decimal, ROUND_HALF_UP\n","from sklearn.preprocessing import StandardScaler\n","import time\n","\n","FILENAME = \"PowerPlantData.csv\" # File path\n","\n","# YOUR CODE HERE to Define a function to load the data\n","df = pd.read_csv(FILENAME)\n","\n","def scale_data(df):\n","\n","    scaler = StandardScaler()\n","    scaler.fit(df)\n","    scaled_data = scaler.transform(df)\n","\n","    return(pd.DataFrame(scaled_data, columns=df.columns, index = df.index))\n","\n","def split_data(df):\n","\n","    feature_cols = ['AT','V','AP','RH']\n","    target_col = ['PE']\n","\n","    features = df[feature_cols]\n","    target = df[target_col]\n","\n","    return features,target\n","\n","def calculate_corelation(df):\n","    return df.corr()\n","\n","def calculate_coff(features,target):\n","    X = features.to_numpy()\n","    y = target.to_numpy()\n","\n","    X_transpose = X.T\n","    coeff = np.linalg.inv(X_transpose @ X) @ X_transpose @ y\n","    return coeff\n","\n","def fit(x, y):\n","    # YOUR CODE HERE\n","    x['Dummy'] = 1\n","    coeff = calculate_coff(x,y)\n","    return coeff\n","\n","def predict(x, intercept, coefficients):\n","    '''\n","    y = b_0 + b_1*x + ... + b_i*x_i\n","    '''\n","    #YOUR CODE HERE\n","    coefficients = coefficients.flatten()\n","    intercept = intercept.flatten()\n","\n","    predictions = np.zeros(x.shape[0])\n","    print(x.shape)\n","\n","    for index, row in x.reset_index(drop=True).iterrows():\n","            predictions[index] = intercept + np.dot(coefficients, row.iloc[:len(coefficients)])\n","\n","    predictions_df = pd.DataFrame(predictions,columns=['PE_Pred'])\n","    return predictions_df\n","\n","def calculate_rmse(target,prediction):\n","    target = target.to_numpy()\n","    prediction = prediction.to_numpy()\n","\n","    squared_errors = (prediction - target) ** 2\n","    mean_squared_error = np.mean(squared_errors)\n","\n","    rmse_value = np.sqrt(mean_squared_error)\n","\n","    return rmse_value\n","\n","def train_test_split(X):\n","    X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n","    num_rows = int(0.7 * len(X))\n","    remain_rows = len(X) - num_rows\n","    train = X.iloc[:num_rows, :].copy()\n","    test = X.tail(remain_rows).copy()\n","    return train, test\n","\n","comm = MPI.COMM_WORLD\n","rank = comm.Get_rank()\n","size = comm.Get_size()\n","\n","def dividing_data(x_train, y_train, size_of_workers):\n","    # Size of the slice\n","    worker_data = []\n","\n","    slice_for_each_worker = int(Decimal(x_train.shape[0]/size_of_workers).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))\n","    # YOUR CODE HERE\n","\n","    row_num = 0\n","    i = 0\n","    for i in range(size_of_workers):\n","\n","        end_index = row_num+slice_for_each_worker\n","        end_index = min(end_index, len(x_train))\n","\n","        worker_data.append((x_train.iloc[row_num:end_index, :].copy(),\n","                            y_train.iloc[row_num:end_index, :].copy()))\n","        row_num = end_index\n","\n","    return worker_data\n","\n","worker_data = None\n","if rank == 0:\n","    features, target = split_data(scale_data(df))\n","    X_train,X_test = train_test_split(features)\n","    y_train,y_test = train_test_split(target)\n","    worker_data = dividing_data(X_train, y_train, 4)\n","\n","recv_data = comm.scatter(worker_data ,root=0)\n","comm.barrier()\n","\n","worker_coeff = fit(recv_data[0],recv_data[1])\n","\n","recv_buff = None\n","recv_buff = comm.gather(worker_coeff,root=0)\n","\n","if rank == 0:\n","    all_coeffs = np.array(recv_buff)\n","    mean_coeffs = np.mean(all_coeffs, axis=0)\n","    print(mean_coeffs)\n","    y_pred = predict(X_test,mean_coeffs[4],mean_coeffs[:4])\n","    rmse_value = calculate_rmse(y_test,y_pred)\n","    print(rmse_value)\n"],"id":"motivated-national","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"experimental-waterproof","scrolled":true},"source":["# YOUR CODE HERE for MPI command\n","!mpirun --allow-run-as-root -np 4 python mpi.py 2> error.log"],"id":"experimental-waterproof","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"protecting-assets"},"source":["#### Exercise 18: Use Sklearn to compare (1 point)\n","\n","Apply the Linear regression on the given data using sklearn package and compare with the above results\n","\n","**Hint:**\n","* Split the data into train and test\n","* Fit the train data and predict the test data using `sklearn Linear Regression`\n","* Compare the coefficients and intercept with above estimated coefficients\n","* calculate loss (RMSE) on test data and predictions and compare"],"id":"protecting-assets"},{"cell_type":"code","metadata":{"id":"applicable-tyler","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747503878780,"user_tz":-330,"elapsed":63,"user":{"displayName":"Shruti Bansal","userId":"12826271742828729339"}},"outputId":"d2041f74-1b7f-4892-ef7c-a34bf57f8c37"},"source":["# YOUR CODE HERE\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Assuming 'df' is your original DataFrame\n","\n","# 1. Split the data into train and test\n","features, target = split_data(scale_data(df))  # Using your existing functions\n","X_train, X_test, y_train, y_test = train_test_split(\n","    features, target, test_size=0.3, random_state=42\n",")\n","\n","# 2. Fit the train data using sklearn Linear Regression\n","sklearn_model = LinearRegression()\n","sklearn_model.fit(X_train, y_train)\n","\n","# 3. Predict the test data\n","sklearn_predictions = sklearn_model.predict(X_test)\n","\n","# 4. Compare coefficients and intercept\n","print(\"Sklearn Coefficients:\", sklearn_model.coef_)\n","print(\"Custom Coefficients:\", coeff[:4])  # Assuming 'coeff' is from your custom fit\n","print(\"Sklearn Intercept:\", sklearn_model.intercept_)\n","print(\"Custom Intercept:\", coeff[4])  # Assuming 'coeff' is from your custom fit\n","\n","# 5. Calculate and compare RMSE\n","sklearn_rmse = np.sqrt(mean_squared_error(y_test, sklearn_predictions))\n","#custom_rmse = calculate_rsme(y_test, prediction(X_test, coeff[4], coeff[:4]))\n","# Using your existing predict and calculate_rsme functions\n","\n","print(\"Sklearn RMSE:\", sklearn_rmse)\n","#print(\"Custom RMSE:\", custom_rmse)"],"id":"applicable-tyler","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sklearn Coefficients: [[-0.86659727 -0.17234908  0.01947262 -0.13665087]]\n","Custom Coefficients: [[-0.86350078]\n"," [-0.17417154]\n"," [ 0.02160293]\n"," [-0.13521023]]\n","Sklearn Intercept: [0.00029321]\n","Custom Intercept: [-1.58120045e-15]\n","Sklearn RMSE: 0.2620609279565783\n"]}]}]}